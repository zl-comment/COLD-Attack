python cold_decoding.py `
 --seed 12 ` --mode "proxy" `
  --pretrained_model "Llama-2-7b-chat-hf" `
  --init-temp 1 `
  --length 20 `
  --max-length 20 `
  --num-iters 2000 `
  --min-iters 0 `
  --goal-weight 100 `
  --rej-weight 100 `
  --stepsize 1e-10 `
  --kl_max_weight 5.0 `
  --noise-iters 1 `
  --win-anneal-iters 1000 `
  --start 0 `
  --end 0 `
  --lr-nll-portion 1.0 `
  --topk 10 `
  --output-lgt-temp 1 `
  --verbose `
  --straight-through `
  --large-noise-iters 50,200,500,1500 `
  --large_gs_std 0.1,0.05,0.01,0.001 `
  --stepsize-ratio 1 `
  --batch-size 8 `
  --print-every 1000 `
  --fp16 `
  --proxy_model "output_hf-v1" `
  --proxy_model_path "D:\ZLCODE\LoRAPrune\output_hf-v1" `
  --wandb_project COLD_Attack_proxy_output_hf-v1_1e-10_KL_5 `
  --wandb